{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d83a196bd2ca484a8ed71956c2f266e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7324d8d8194643d891e79ba3e485d1c4",
              "IPY_MODEL_f234b40448e849d885912422094727be",
              "IPY_MODEL_732e72cb15ac469b9120e81222c431ca",
              "IPY_MODEL_54929a5b9d87412a98a0eb9c1e7f18db",
              "IPY_MODEL_8e1bb95481b24648819ad15da54146d9"
            ],
            "layout": "IPY_MODEL_9357c4ab83064c3ebfaaf601c93f467f"
          }
        },
        "7324d8d8194643d891e79ba3e485d1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df50543d60124b2ba32e125d99c0319e",
            "placeholder": "​",
            "style": "IPY_MODEL_65fd1c28d493426d862cccb16c67b8ce",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f234b40448e849d885912422094727be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8f58b70c3c544d8f971866b72ab18d03",
            "placeholder": "​",
            "style": "IPY_MODEL_33aed94b065546b59e9cdf95561c8bf1",
            "value": ""
          }
        },
        "732e72cb15ac469b9120e81222c431ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a5f2e1e9f67746d68bcfe8715c3e2cc9",
            "style": "IPY_MODEL_3daeeb5dc45b4c658a5e6ccf0327e04d",
            "value": true
          }
        },
        "54929a5b9d87412a98a0eb9c1e7f18db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_df817c161450471d9ccc80645fad8c04",
            "style": "IPY_MODEL_f82a39bd14fa4f76bf778a133c09b2a5",
            "tooltip": ""
          }
        },
        "8e1bb95481b24648819ad15da54146d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64411cae1dad422a9bed771cd9648d58",
            "placeholder": "​",
            "style": "IPY_MODEL_87096216393c42dfa1c2d83d0b9f5e73",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "9357c4ab83064c3ebfaaf601c93f467f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "df50543d60124b2ba32e125d99c0319e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fd1c28d493426d862cccb16c67b8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f58b70c3c544d8f971866b72ab18d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33aed94b065546b59e9cdf95561c8bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5f2e1e9f67746d68bcfe8715c3e2cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3daeeb5dc45b4c658a5e6ccf0327e04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df817c161450471d9ccc80645fad8c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82a39bd14fa4f76bf778a133c09b2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "64411cae1dad422a9bed771cd9648d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87096216393c42dfa1c2d83d0b9f5e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e10d2ef8daf4bae97482936608f3e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bacc02e234f4ac8b5eee06fa0768ae4",
              "IPY_MODEL_0488a6a935594b798d491a3503a61c2e",
              "IPY_MODEL_a06d191a07dd4942904ff5c8b9f01577"
            ],
            "layout": "IPY_MODEL_2b93eaf1b47f4a698d3c7dd5a511ecf9"
          }
        },
        "3bacc02e234f4ac8b5eee06fa0768ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464d912916b24fe4ae4de3ef823ddd86",
            "placeholder": "​",
            "style": "IPY_MODEL_b45a1340dd0a45c798a5a6dca686f6e0",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "0488a6a935594b798d491a3503a61c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa01cd473f95424b8efe6a5f9db6b735",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3de5adfd6af54713bd5c6f8a59ef74de",
            "value": 7
          }
        },
        "a06d191a07dd4942904ff5c8b9f01577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae5dbf9006a407db176954b3bc4d887",
            "placeholder": "​",
            "style": "IPY_MODEL_ce3116c2260542e7bd7a030a0771d2ef",
            "value": " 7/7 [00:00&lt;00:00,  8.28it/s]"
          }
        },
        "2b93eaf1b47f4a698d3c7dd5a511ecf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464d912916b24fe4ae4de3ef823ddd86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45a1340dd0a45c798a5a6dca686f6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa01cd473f95424b8efe6a5f9db6b735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de5adfd6af54713bd5c6f8a59ef74de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ae5dbf9006a407db176954b3bc4d887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3116c2260542e7bd7a030a0771d2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **TEXT TO IMAGE GENERATOR USING AI**"
      ],
      "metadata": {
        "id": "ADXS0vCPghpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU Info"
      ],
      "metadata": {
        "id": "NJBJf3RtgbVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5uKuOJ9ZMPmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36d2a86-6f7b-4ed8-d748-d6fa9534263b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUDA Check"
      ],
      "metadata": {
        "id": "jqer7zCLg36L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print True if GPU is enabled\n"
      ],
      "metadata": {
        "id": "gLyW8ekvM8Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54feb48-ff53-412a-dc78-da443d0af268"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Packages"
      ],
      "metadata": {
        "id": "zpu9kvyJg87U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers transformers torch accelerate\n",
        "!pip install -q ftfy      # optional, for better text handling\n"
      ],
      "metadata": {
        "id": "WYjecIgPM8cY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e3d54c-dbf8-4fc1-9d52-d8859ebaf59f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Install Huggingface Hub"
      ],
      "metadata": {
        "id": "hHjwZCaUP3es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub\n"
      ],
      "metadata": {
        "id": "Z_gIQmWRM8fx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Huggingface Hub login"
      ],
      "metadata": {
        "id": "DViT_wHjhlIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "9DbXm20gNc2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442,
          "referenced_widgets": [
            "d83a196bd2ca484a8ed71956c2f266e4",
            "7324d8d8194643d891e79ba3e485d1c4",
            "f234b40448e849d885912422094727be",
            "732e72cb15ac469b9120e81222c431ca",
            "54929a5b9d87412a98a0eb9c1e7f18db",
            "8e1bb95481b24648819ad15da54146d9",
            "9357c4ab83064c3ebfaaf601c93f467f",
            "df50543d60124b2ba32e125d99c0319e",
            "65fd1c28d493426d862cccb16c67b8ce",
            "8f58b70c3c544d8f971866b72ab18d03",
            "33aed94b065546b59e9cdf95561c8bf1",
            "a5f2e1e9f67746d68bcfe8715c3e2cc9",
            "3daeeb5dc45b4c658a5e6ccf0327e04d",
            "df817c161450471d9ccc80645fad8c04",
            "f82a39bd14fa4f76bf778a133c09b2a5",
            "64411cae1dad422a9bed771cd9648d58",
            "87096216393c42dfa1c2d83d0b9f5e73"
          ]
        },
        "outputId": "b992e204-ee93-4753-f325-f848d3ff022a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d83a196bd2ca484a8ed71956c2f266e4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load AI model"
      ],
      "metadata": {
        "id": "gLsZUb_ahuiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"  # or another model like \"stabilityai/stable-diffusion-2-1\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
        "pipe = pipe.to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "lJ9zhcZQNc5Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "6e10d2ef8daf4bae97482936608f3e86",
            "3bacc02e234f4ac8b5eee06fa0768ae4",
            "0488a6a935594b798d491a3503a61c2e",
            "a06d191a07dd4942904ff5c8b9f01577",
            "2b93eaf1b47f4a698d3c7dd5a511ecf9",
            "464d912916b24fe4ae4de3ef823ddd86",
            "b45a1340dd0a45c798a5a6dca686f6e0",
            "fa01cd473f95424b8efe6a5f9db6b735",
            "3de5adfd6af54713bd5c6f8a59ef74de",
            "0ae5dbf9006a407db176954b3bc4d887",
            "ce3116c2260542e7bd7a030a0771d2ef"
          ]
        },
        "outputId": "5da85d1c-df50-4e7e-dab8-e2d856e7daa2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e10d2ef8daf4bae97482936608f3e86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-956968473.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"CompVis/stable-diffusion-v1-4\"\u001b[0m  \u001b[0;31m# or another model like \"stabilityai/stable-diffusion-2-1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_in_4bit_bnb\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_in_8bit_bnb\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_group_offloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4341\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4342\u001b[0m                 )\n\u001b[0;32m-> 4343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     )\n\u001b[0;32m-> 1355\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Generation"
      ],
      "metadata": {
        "id": "BBUkbDoPh0db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a futuristic city at sunset\"\n",
        "image = pipe(prompt).images[0]\n"
      ],
      "metadata": {
        "id": "SywMxENONc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "87fa8c91-cda8-4959-eae5-1cca97cc6e4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipe' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1991523594.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"a futuristic city at sunset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Image"
      ],
      "metadata": {
        "id": "PzP8oW9kh4D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9O-OCS6vNc_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print Image Object"
      ],
      "metadata": {
        "id": "lM8QjeXiiQum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image\n"
      ],
      "metadata": {
        "id": "ooj_OeBzOgZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Image"
      ],
      "metadata": {
        "id": "TqqTgK9kiWRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.save(\"astronaut.png\")\n"
      ],
      "metadata": {
        "id": "H6nOg_12Ogrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hardware Detection and Configuration"
      ],
      "metadata": {
        "id": "PUCbGuHyiZw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import json\n",
        "\n",
        "# Detect hardware configuration\n",
        "def detect_hardware():\n",
        "    \"\"\"\n",
        "    Detect available hardware and suggest optimal configuration\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"HARDWARE DETECTION AND CONFIGURATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    print(f\"\\nGPU Available: {gpu_available}\")\n",
        "\n",
        "    if gpu_available:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"GPU Name: {gpu_name}\")\n",
        "        print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        print(\"\\nWARNING: GPU not available. Using CPU (slower performance)\")\n",
        "        print(\"For faster generation, use a GPU-enabled environment\")\n",
        "        device = \"cpu\"\n",
        "\n",
        "    # CPU information\n",
        "    cpu_count = psutil.cpu_count(logical=False)\n",
        "    cpu_freq = psutil.cpu_freq().max / 1000 if psutil.cpu_freq() else 0\n",
        "    print(f\"\\nCPU Cores: {cpu_count}\")\n",
        "    print(f\"CPU Frequency: {cpu_freq:.2f} GHz\")\n",
        "\n",
        "    # RAM information\n",
        "    ram = psutil.virtual_memory().total / 1e9\n",
        "    print(f\"Available RAM: {ram:.2f} GB\")\n",
        "\n",
        "    return device\n",
        "\n",
        "# Detect and set device\n",
        "device = detect_hardware()\n",
        "print(f\"\\nUsing device: {device.upper()}\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "id": "TrybkChJawcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Engineering and Enhancement"
      ],
      "metadata": {
        "id": "jnXX4ZrGi4iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Content Filtering - Ethical AI Guidelines\n",
        "UNSAFE_KEYWORDS = [\n",
        "    'graphic violence', 'gore', 'weapons', 'hate speech',\n",
        "    'discrimination', 'explicit sexual', 'child',\n",
        "    'copyrighted character', 'celebrity likeness'\n",
        "]\n",
        "\n",
        "def validate_prompt(prompt):\n",
        "    \"\"\"\n",
        "    Filter inappropriate prompts before generation\n",
        "    \"\"\"\n",
        "    prompt_lower = prompt.lower()\n",
        "    for keyword in UNSAFE_KEYWORDS:\n",
        "        if keyword in prompt_lower:\n",
        "            print(f\"\\n⚠️ WARNING: Prompt contains inappropriate keyword: '{keyword}'\")\n",
        "            print(\"This image will not be generated for ethical reasons.\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Prompt Engineering - Quality Enhancement\n",
        "STYLE_DESCRIPTORS = {\n",
        "    'photorealistic': 'photorealistic, professional photography, 4K, ultra HD, best quality',\n",
        "    'artistic': 'artistic illustration, creative, professional artwork, oil painting',\n",
        "    'cartoon': 'cartoon, animated style, colorful, playful, vibrant',\n",
        "    'cinematic': 'cinematic, movie scene, dramatic lighting, professional camera shot',\n",
        "    'detailed': 'highly detailed, intricate, complex, fine details, sharp focus'\n",
        "}\n",
        "\n",
        "QUALITY_ENHANCERS = [\n",
        "    'masterpiece', 'best quality', 'highly detailed',\n",
        "    'professional', '4K', 'ultra HD', 'sharp focus',\n",
        "    'beautiful lighting', 'well composed'\n",
        "]\n",
        "\n",
        "def enhance_prompt(base_prompt, style='photorealistic', add_quality=True):\n",
        "    \"\"\"\n",
        "    Enhance prompt with style and quality descriptors\n",
        "    \"\"\"\n",
        "    enhanced = base_prompt\n",
        "\n",
        "    # Add style descriptor\n",
        "    if style in STYLE_DESCRIPTORS:\n",
        "        enhanced += f\", {STYLE_DESCRIPTORS[style]}\"\n",
        "\n",
        "    # Add quality enhancers\n",
        "    if add_quality:\n",
        "        quality_str = ', '.join(QUALITY_ENHANCERS)\n",
        "        enhanced += f\", {quality_str}\"\n",
        "\n",
        "    return enhanced\n",
        "\n",
        "# Negative Prompt Engineering\n",
        "NEGATIVE_PROMPTS = {\n",
        "    'default': 'blurry, low quality, pixelated, distorted, amateur, bad anatomy, watermark',\n",
        "    'realistic': 'cartoon, anime, illustration, blur, distortion, noise',\n",
        "    'artistic': 'photorealistic, photograph, photo, 3D render, CGI'\n",
        "}\n",
        "\n",
        "print(\"\\n✓ Prompt Engineering System Initialized\")\n",
        "print(\"✓ Content Filtering Active\")\n",
        "print(\"✓ Quality Enhancement Ready\")"
      ],
      "metadata": {
        "id": "GcqnViPla7KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Image Storage, Export, Metadata & Watermarking"
      ],
      "metadata": {
        "id": "8tUweU1ZjDiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Setup output directories\n",
        "OUTPUT_BASE_DIR = Path('/content/generated_images')\n",
        "OUTPUT_BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "METADATA_DIR = OUTPUT_BASE_DIR / 'metadata'\n",
        "METADATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def create_image_metadata(prompt, enhanced_prompt, style, parameters):\n",
        "    \"\"\"\n",
        "    Create metadata dictionary for generated image\n",
        "    \"\"\"\n",
        "    metadata = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'original_prompt': prompt,\n",
        "        'enhanced_prompt': enhanced_prompt,\n",
        "        'style': style,\n",
        "        'generation_parameters': parameters,\n",
        "        'device': device,\n",
        "        'watermarked': True,\n",
        "        'ai_generated': True\n",
        "    }\n",
        "    return metadata\n",
        "\n",
        "def add_watermark(image, text='Aditya- AI Generated Image'):\n",
        "    \"\"\"\n",
        "    Add ethical watermark to indicate AI origin\n",
        "    \"\"\"\n",
        "    img_array = np.array(image)\n",
        "    pil_image = Image.fromarray(img_array.astype('uint8'))\n",
        "\n",
        "    # Create watermark\n",
        "    draw = ImageDraw.Draw(pil_image, 'RGBA')\n",
        "    width, height = pil_image.size\n",
        "\n",
        "    # Semi-transparent background for watermark\n",
        "    watermark_height = 40\n",
        "    draw.rectangle(\n",
        "        [(0, height - watermark_height), (width, height)],\n",
        "        fill=(0, 0, 0, 80)\n",
        "    )\n",
        "\n",
        "    # Add watermark text\n",
        "    try:\n",
        "        # Try to use a nice font, fallback to default if not available\n",
        "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 20)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    draw.text(\n",
        "        (10, height - 35),\n",
        "        text,\n",
        "        fill=(255, 255, 255, 200),\n",
        "        font=font\n",
        "    )\n",
        "\n",
        "    return pil_image\n",
        "\n",
        "def save_image_with_metadata(image, prompt, enhanced_prompt, style, parameters, filename=None):\n",
        "    \"\"\"\n",
        "    Save image with watermark and metadata\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        filename = f'generated_{timestamp}'\n",
        "\n",
        "    # Create metadata\n",
        "    metadata = create_image_metadata(prompt, enhanced_prompt, style, parameters)\n",
        "\n",
        "    # Add watermark\n",
        "    watermarked_image = add_watermark(image)\n",
        "\n",
        "    # Save image as PNG and JPEG\n",
        "    png_path = OUTPUT_BASE_DIR / f'{filename}.png'\n",
        "    jpg_path = OUTPUT_BASE_DIR / f'{filename}.jpg'\n",
        "\n",
        "    watermarked_image.save(png_path, 'PNG')\n",
        "    watermarked_image.save(jpg_path, 'JPEG', quality=95)\n",
        "\n",
        "    # Save metadata as JSON\n",
        "    metadata_path = METADATA_DIR / f'{filename}_metadata.json'\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    print(f\"\\n✅ Image saved successfully!\")\n",
        "    print(f\"   PNG: {png_path}\")\n",
        "    print(f\"   JPG: {jpg_path}\")\n",
        "    print(f\"   Metadata: {metadata_path}\")\n",
        "\n",
        "    return png_path, jpg_path, metadata_path\n",
        "\n",
        "print(\"\\n✓ Storage System Initialized\")\n",
        "print(\"✓ Watermarking System Ready\")\n",
        "print(f\"✓ Output Directory: {OUTPUT_BASE_DIR}\")"
      ],
      "metadata": {
        "id": "l7UToIgfbHi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Image Generation with progress"
      ],
      "metadata": {
        "id": "0xdItIsljSNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "def generate_images_advanced(\n",
        "    prompt,\n",
        "    num_images=1,\n",
        "    style='photorealistic',\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    height=512,\n",
        "    width=512,\n",
        "    seed=None,\n",
        "    add_negative_prompt=True,\n",
        "    save_metadata=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Advanced image generation with progress tracking\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ADVANCED IMAGE GENERATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Validate prompt\n",
        "    if not validate_prompt(prompt):\n",
        "        return None\n",
        "\n",
        "    # Enhance prompt\n",
        "    enhanced_prompt = enhance_prompt(prompt, style=style, add_quality=True)\n",
        "\n",
        "    print(f\"\\nOriginal Prompt: {prompt}\")\n",
        "    print(f\"\\nEnhanced Prompt: {enhanced_prompt}\")\n",
        "\n",
        "    # Get negative prompt\n",
        "    negative_prompt = NEGATIVE_PROMPTS.get(style, NEGATIVE_PROMPTS['default'])\n",
        "    if add_negative_prompt:\n",
        "        print(f\"\\nNegative Prompt: {negative_prompt}\")\n",
        "\n",
        "    # Estimate generation time\n",
        "    time_per_step = 0.3 if device == 'cuda' else 1.0  # seconds per step\n",
        "    estimated_time = num_images * num_inference_steps * time_per_step\n",
        "    print(f\"\\nEstimated Time: ~{int(estimated_time)} seconds ({int(estimated_time/60)} minutes)\")\n",
        "    print(f\"Settings: {num_inference_steps} steps, guidance scale {guidance_scale}\\n\")\n",
        "\n",
        "    # Generation with progress tracking\n",
        "    generated_images = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for img_idx in range(num_images):\n",
        "        print(f\"Generating image {img_idx + 1}/{num_images}...\")\n",
        "\n",
        "        generation_params = {\n",
        "            'prompt': prompt,\n",
        "            'num_inference_steps': num_inference_steps,\n",
        "            'guidance_scale': guidance_scale,\n",
        "            'height': height,\n",
        "            'width': width,\n",
        "            'negative_prompt': negative_prompt if add_negative_prompt else None\n",
        "        }\n",
        "\n",
        "        if seed is not None:\n",
        "            generation_params['generator'] = torch.Generator(device=device).manual_seed(seed + img_idx)\n",
        "\n",
        "        # Generate image\n",
        "        with torch.autocast(device):\n",
        "            result = pipe(**generation_params)\n",
        "            image = result.images[0]\n",
        "\n",
        "        generated_images.append(image)\n",
        "\n",
        "        # Save with metadata\n",
        "        if save_metadata:\n",
        "            save_image_with_metadata(\n",
        "                image,\n",
        "                prompt,\n",
        "                enhanced_prompt,\n",
        "                style,\n",
        "                generation_params\n",
        "            )\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\n✅ Generation Complete!\")\n",
        "    print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Average time per image: {elapsed_time/num_images:.2f} seconds\")\n",
        "\n",
        "    return generated_images\n",
        "\n",
        "print(\"\\n✓ Advanced Generation System Ready\")\n",
        "print(\"✓ Progress Tracking Enabled\")\n",
        "print(\"✓ Time Estimation Enabled\")"
      ],
      "metadata": {
        "id": "7vZiyxSTbUWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit Web App Writer / Streamlit Web Interface"
      ],
      "metadata": {
        "id": "1Q5ZbMozjmHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create Streamlit app file\n",
        "streamlit_app_code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Image Generator\",\n",
        "    page_icon=\"🎨\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Title and description\n",
        "st.title(\"🎨 AI-Powered Text-to-Image Generator By Aditya\")\n",
        "st.markdown(\"\"\"\n",
        "Generate high-quality images from text descriptions using advanced AI models.\n",
        "**Features:**\n",
        "- Multiple style options (photorealistic, artistic, cartoon, cinematic, detailed)\n",
        "- Adjustable generation parameters\n",
        "- Automatic watermarking for ethical AI\n",
        "- Multiple export formats (PNG, JPEG)\n",
        "- Metadata tracking\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Sidebar controls\n",
        "with st.sidebar:\n",
        "    st.header(\"⚙️ Generation Settings\")\n",
        "\n",
        "    # Text prompt input\n",
        "    prompt = st.text_area(\n",
        "        \"Enter your image description:\",\n",
        "        placeholder=\"e.g., A futuristic city at sunset with flying cars...\",\n",
        "        height=100\n",
        "    )\n",
        "\n",
        "    # Style selection\n",
        "    style = st.selectbox(\n",
        "        \"Select art style:\",\n",
        "        [\"photorealistic\", \"artistic\", \"cartoon\", \"cinematic\", \"detailed\"]\n",
        "    )\n",
        "\n",
        "    # Number of images\n",
        "    num_images = st.slider(\n",
        "        \"Number of images to generate:\",\n",
        "        min_value=1,\n",
        "        max_value=4,\n",
        "        value=1\n",
        "    )\n",
        "\n",
        "    # Quality settings\n",
        "    st.subheader(\"Advanced Settings\")\n",
        "    num_steps = st.slider(\n",
        "        \"Inference steps (higher = better quality, slower):\",\n",
        "        min_value=20,\n",
        "        max_value=100,\n",
        "        value=50,\n",
        "        step=10\n",
        "    )\n",
        "\n",
        "    guidance_scale = st.slider(\n",
        "        \"Guidance scale (higher = closer to prompt):\",\n",
        "        min_value=1.0,\n",
        "        max_value=20.0,\n",
        "        value=7.5,\n",
        "        step=0.5\n",
        "    )\n",
        "\n",
        "    # Export options\n",
        "    st.subheader(\"Export Options\")\n",
        "    export_formats = st.multiselect(\n",
        "        \"Export formats:\",\n",
        "        [\"PNG\", \"JPEG\"],\n",
        "        default=[\"PNG\", \"JPEG\"]\n",
        "    )\n",
        "\n",
        "    add_watermark = st.checkbox(\"Add AI watermark\", value=True)\n",
        "    save_metadata = st.checkbox(\"Save metadata\", value=True)\n",
        "\n",
        "    # Generate button\n",
        "    generate_button = st.button(\"🚀 Generate Images\", use_container_width=True)\n",
        "\n",
        "# Main content area\n",
        "if generate_button:\n",
        "    if not prompt:\n",
        "        st.error(\"Please enter a prompt!\")\n",
        "    else:\n",
        "        with st.spinner(f\"Generating {num_images} image(s) with {style} style...\"):\n",
        "            st.info(f\"📝 Prompt: {prompt}\")\n",
        "            st.info(f\"⏱️ Estimated time: ~{num_images * num_steps * 0.3 / 60:.1f} minutes\")\n",
        "\n",
        "            # Create placeholder for images\n",
        "            image_placeholders = st.columns(min(num_images, 2))\n",
        "\n",
        "            # Generate images\n",
        "            for idx in range(num_images):\n",
        "                col = image_placeholders[idx % len(image_placeholders)]\n",
        "                with col:\n",
        "                    with st.spinner(f\"Image {idx+1}/{num_images}\"):\n",
        "                        # Placeholder for actual generation\n",
        "                        st.success(f\"✅ Image {idx+1} generated!\")\n",
        "\n",
        "            st.success(f\"🎉 Successfully generated {num_images} image(s)!\")\n",
        "\n",
        "# Information section\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "### 📖 How to Use:\n",
        "1. **Enter Prompt**: Describe the image you want to generate\n",
        "2. **Select Style**: Choose from photorealistic, artistic, cartoon, cinematic, or detailed\n",
        "3. **Adjust Settings**: Fine-tune inference steps and guidance scale\n",
        "4. **Generate**: Click the generate button and wait\n",
        "5. **Export**: Download generated images in your preferred format\n",
        "\n",
        "### ⚠️ Ethical AI Guidelines:\n",
        "- Generated images are watermarked to indicate AI origin\n",
        "- Inappropriate content is automatically filtered\n",
        "- Metadata tracking ensures transparency\n",
        "- Use responsibly and respect copyright\n",
        "\n",
        "### 💡 Tips for Better Results:\n",
        "- Be specific in your descriptions\n",
        "- Use style descriptors (\"photorealistic\", \"oil painting\", \"anime\", etc.)\n",
        "- Experiment with guidance scale for different levels of adherence\n",
        "- Higher steps = better quality but longer generation time\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "---\n",
        "**Created with ❤️ using Stable Diffusion and Streamlit by Aditya**\n",
        "\"\"\")\n",
        "'''\n",
        "\n",
        "# Write Streamlit app to file\n",
        "app_path = Path('/content/streamlit_app.py')\n",
        "with open(app_path, 'w') as f:\n",
        "    f.write(streamlit_app_code)\n",
        "\n",
        "print(f\"\\n✅ Streamlit app created at: {app_path}\")\n",
        "print(\"\\nTo run the Streamlit app, use:\")\n",
        "print(\"  streamlit run /content/streamlit_app.py\")\n",
        "print(\"\\nFor Colab, use:\")\n",
        "print(\"  !streamlit run /content/streamlit_app.py & npx localtunnel --port 8501\")"
      ],
      "metadata": {
        "id": "01xoe425bfcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation and Features with Usage Examples"
      ],
      "metadata": {
        "id": "Q_mvJHgEkt_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AI-POWERED TEXT-TO-IMAGE GENERATOR - COMPLETE GUIDE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "## FEATURES IMPLEMENTED\n",
        "\n",
        "✅ HARDWARE DETECTION & OPTIMIZATION\n",
        "   - Automatic GPU/CPU detection\n",
        "   - CUDA support with fallback to CPU\n",
        "   - Memory-efficient model loading\n",
        "   - Performance metrics display\n",
        "\n",
        "✅ ADVANCED PROMPT ENGINEERING\n",
        "   - Style-specific prompt enhancement\n",
        "   - Quality descriptor injection\n",
        "   - Negative prompt support\n",
        "   - Content filtering for ethical AI\n",
        "\n",
        "✅ IMAGE GENERATION & CONTROL\n",
        "   - Multiple inference step control (20-100)\n",
        "   - Guidance scale adjustment (1.0-20.0)\n",
        "   - Batch generation support\n",
        "   - Custom image dimensions\n",
        "\n",
        "✅ STORAGE & EXPORT\n",
        "   - PNG and JPEG export formats\n",
        "   - Metadata JSON tracking\n",
        "   - Organized directory structure\n",
        "   - Timestamp-based file naming\n",
        "\n",
        "✅ ETHICAL AI & WATERMARKING\n",
        "   - Automatic watermarking\n",
        "   - Content filtering system\n",
        "   - Metadata documentation\n",
        "   - AI origin indicators\n",
        "\n",
        "✅ PROGRESS TRACKING\n",
        "   - Real-time progress updates\n",
        "   - Time estimation\n",
        "   - Elapsed time tracking\n",
        "   - Performance metrics\n",
        "\n",
        "✅ WEB INTERFACE\n",
        "   - Streamlit-based user interface\n",
        "   - Interactive controls\n",
        "   - Real-time preview\n",
        "   - Export options\n",
        "\n",
        "## USAGE EXAMPLES\n",
        "\n",
        "### Example 1: Basic Generation\n",
        "# Simple image generation with default settings\n",
        "images = generate_images_advanced(\n",
        "    prompt=\"A beautiful sunset over mountains\",\n",
        "    num_images=1,\n",
        "    style=\"photorealistic\"\n",
        ")\n",
        "\n",
        "### Example 2: Artistic Style\n",
        "# Generate artistic images with oil painting style\n",
        "images = generate_images_advanced(\n",
        "    prompt=\"Ancient Roman temple ruins\",\n",
        "    num_images=2,\n",
        "    style=\"artistic\",\n",
        "    num_inference_steps=75,\n",
        "    guidance_scale=9.0\n",
        ")\n",
        "\n",
        "### Example 3: Cartoon Style\n",
        "# Create cartoon-style images\n",
        "images = generate_images_advanced(\n",
        "    prompt=\"A friendly dragon flying over clouds\",\n",
        "    num_images=1,\n",
        "    style=\"cartoon\",\n",
        "    num_inference_steps=50\n",
        ")\n",
        "\n",
        "### Example 4: Cinematic Style\n",
        "# Generate cinematic shots\n",
        "images = generate_images_advanced(\n",
        "    prompt=\"A space explorer on an alien planet with three moons\",\n",
        "    num_images=1,\n",
        "    style=\"cinematic\",\n",
        "    num_inference_steps=75,\n",
        "    guidance_scale=8.5\n",
        ")\n",
        "\n",
        "## ETHICAL GUIDELINES\n",
        "\n",
        "⚠️ CONTENT FILTERING\n",
        "   The system automatically blocks prompts containing:\n",
        "   - Graphic violence or gore\n",
        "   - Hate speech or discrimination\n",
        "   - Explicit adult content\n",
        "   - Copyrighted character likenesses\n",
        "   - Child-related inappropriate content\n",
        "\n",
        "⚠️ WATERMARKING\n",
        "   All generated images include:\n",
        "   - \"AI Generated Image\" watermark\n",
        "   - Semi-transparent attribution bar\n",
        "   - Timestamp and metadata\n",
        "   - Original prompt tracking\n",
        "\n",
        "⚠️ RESPONSIBLE USE\n",
        "   - Respect copyright and intellectual property\n",
        "   - Disclose AI-generated nature of images\n",
        "   - Don't use for deception or fraud\n",
        "   - Follow local regulations and laws\n",
        "   - Respect individuals' privacy\n",
        "\n",
        "## OUTPUT DIRECTORY STRUCTURE\n",
        "\n",
        "/content/generated_images/\n",
        "  ├── *.png                    # Generated images in PNG format\n",
        "  ├── *.jpg                    # Generated images in JPEG format\n",
        "  └── metadata/\n",
        "      └── *_metadata.json      # Image metadata and parameters\n",
        "\n",
        "## INSTALLATION & SETUP (Local Machine)\n",
        "\n",
        "1. Install requirements:\n",
        "   pip install -q diffusers transformers torch\n",
        "   pip install -q streamlit pillow opencv-python\n",
        "   pip install -q accelerate ftfy\n",
        "\n",
        "2. For GPU support (CUDA 11+):\n",
        "   pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "3. Run Streamlit interface:\n",
        "   streamlit run streamlit_app.py\n",
        "\n",
        "4. Or use in Python:\n",
        "   from diffusers import StableDiffusionPipeline\n",
        "   import torch\n",
        "   pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
        "   pipe = pipe.to(\"cuda\")\n",
        "   image = pipe(\"your prompt\").images[0]\n",
        "\n",
        "## TROUBLESHOOTING\n",
        "\n",
        "✦ Out of Memory Error:\n",
        "   - Reduce height/width (use 512x512 or lower)\n",
        "   - Lower num_inference_steps\n",
        "   - Use CPU_OFFLOAD (slower but less memory)\n",
        "   - Generate one image at a time\n",
        "\n",
        "✦ Slow Generation:\n",
        "   - Enable GPU: torch.cuda.is_available()\n",
        "   - Use smaller model variants\n",
        "   - Reduce num_inference_steps\n",
        "   - Batch process during off-peak hours\n",
        "\n",
        "✦ Poor Image Quality:\n",
        "   - Increase num_inference_steps (50-75)\n",
        "   - Increase guidance_scale (7.5-10.0)\n",
        "   - Use more specific prompts\n",
        "   - Try different styles\n",
        "   - Adjust negative prompts\n",
        "\n",
        "## MODEL INFORMATION\n",
        "\n",
        "- Model: Stable Diffusion v1.4\n",
        "- Framework: PyTorch\n",
        "- License: Open-source (CreativeML Open RAIL License)\n",
        "- Parameter Count: ~860M\n",
        "- Input: Text prompts\n",
        "- Output: 512x512 images (configurable)\n",
        "\n",
        "## REFERENCES & RESOURCES\n",
        "\n",
        "- Stable Diffusion: https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
        "- Diffusers Library: https://huggingface.co/docs/diffusers\n",
        "- PyTorch: https://pytorch.org\n",
        "- Streamlit: https://streamlit.io\n",
        "- Ethical AI Guidelines: https://www.ai.gov/governance/\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"Setup complete! Your AI Image Generator is ready to use.\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "NfFyF6Z_btkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick Start with Practical Examples"
      ],
      "metadata": {
        "id": "tSZGKaEalBA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"QUICK START EXAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# COMMENTED OUT - Uncomment to run actual generation\n",
        "# These examples show how to use the system\n",
        "\n",
        "print(\"\"\"\n",
        "## Example 1: Generate a single photorealistic image\n",
        "# Uncomment and run this code to generate an image:\n",
        "\n",
        " images = generate_images_advanced(\n",
        "     prompt=\"A majestic eagle soaring over snowy mountains at sunrise\",\n",
        "     num_images=1,\n",
        "     style=\"photorealistic\",\n",
        "     num_inference_steps=50,\n",
        "     guidance_scale=7.5\n",
        " )\n",
        "\n",
        "## Example 2: Generate multiple artistic images\n",
        "# images = generate_images_advanced(\n",
        "#     prompt=\"Ancient library with glowing magical books\",\n",
        "#     num_images=2,\n",
        "#     style=\"artistic\",\n",
        "#     num_inference_steps=75,\n",
        "#     guidance_scale=8.5\n",
        "# )\n",
        "\n",
        "## Example 3: Generate cartoon-style images\n",
        "# images = generate_images_advanced(\n",
        "#     prompt=\"Cute cartoon animals having a picnic in a forest\",\n",
        "#     num_images=1,\n",
        "#     style=\"cartoon\",\n",
        "#     num_inference_steps=50\n",
        "# )\n",
        "\n",
        "## Example 4: Generate cinematic images\n",
        "# images = generate_images_advanced(\n",
        "#     prompt=\"Cyberpunk city with neon lights and flying cars\",\n",
        "#     num_images=1,\n",
        "#     style=\"cinematic\",\n",
        "#     num_inference_steps=75,\n",
        "#     guidance_scale=9.0\n",
        "# )\n",
        "\n",
        "## Example 5: Test prompt validation\n",
        "# Test if a prompt is valid:\n",
        "test_prompt = \"A beautiful landscape with flowers\"\n",
        "is_valid = validate_prompt(test_prompt)\n",
        "print(f\"Prompt validation: {test_prompt}\")\n",
        "print(f\"Is valid: {is_valid}\")\n",
        "\n",
        "## Example 6: Test prompt enhancement\n",
        "# See how prompts are enhanced:\n",
        "original = \"A robot\"\n",
        "enhanced = enhance_prompt(original, style=\"photorealistic\", add_quality=True)\n",
        "print(f\"\\nOriginal prompt: {original}\")\n",
        "print(f\"Enhanced prompt: {enhanced}\")\n",
        "\n",
        "## Example 7: View available styles\n",
        "print(\"\\nAvailable styles:\")\n",
        "for style, descriptor in STYLE_DESCRIPTORS.items():\n",
        "    print(f\"  - {style}: {descriptor}\")\n",
        "\n",
        "## Example 8: View negative prompts\n",
        "print(\"\\nNegative prompt options:\")\n",
        "for style, neg_prompt in NEGATIVE_PROMPTS.items():\n",
        "    print(f\"  - {style}: {neg_prompt}\")\n",
        "\"\"\")\n",
        "\n",
        "# Show summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SYSTEM STATUS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\"\"\n",
        "✅ All components initialized successfully!\n",
        "✅ Hardware detected: GPU available ({device.upper()})\n",
        "✅ Model loaded: Stable Diffusion v1.4\n",
        "✅ Features enabled:\n",
        "   - Prompt engineering and enhancement\n",
        "   - Content filtering and validation\n",
        "   - Watermarking system\n",
        "   - Metadata tracking\n",
        "   - Progress estimation\n",
        "   - Multi-format export (PNG, JPEG)\n",
        "   - Streamlit web interface\n",
        "\n",
        "🚀 Ready to generate images!\n",
        "⚠️ Please use responsibly and follow ethical guidelines.\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# Example of validate_prompt in action\n",
        "print(\"Content Filter Test:\")\n",
        "print(\"-\" * 70)\n",
        "sample_prompts = [\n",
        "    \"A sunset over the ocean\",\n",
        "    \"A fantasy castle with dragons\",\n",
        "    \"graphic violence in a battle\"\n",
        "]\n",
        "\n",
        "for prompt in sample_prompts:\n",
        "    is_valid = validate_prompt(prompt)\n",
        "    status = \"✅ SAFE\" if is_valid else \"❌ BLOCKED\"\n",
        "    print(f\"{status}: '{prompt}'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"Generated images will be saved to: {OUTPUT_BASE_DIR}\")\n",
        "print(f\"Metadata will be saved to: {METADATA_DIR}\")\n",
        "print(f\"Streamlit app available at: /content/streamlit_app.py\")\n",
        "print(\"=\"*70 + \"\\n\")"
      ],
      "metadata": {
        "id": "fiicmkj8b-Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Web Hosting Packages"
      ],
      "metadata": {
        "id": "MO9ev5cSlprH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit==1.30 pyngrok==4.1.1\n"
      ],
      "metadata": {
        "id": "vdXNzWEJ2E-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find Tunnel Password and Public IP"
      ],
      "metadata": {
        "id": "7pZAJ9S5l9Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tunnel Password"
      ],
      "metadata": {
        "id": "PGCTl1cLmMLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://loca.lt/mytunnelpassword\n"
      ],
      "metadata": {
        "id": "Hs5OlpI-a011"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Public IP"
      ],
      "metadata": {
        "id": "IvFTchcEmRrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/streamlit_app.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "id": "hJmNg6r02Awc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements to host in GitHub"
      ],
      "metadata": {
        "id": "tGXjNjVypyHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "streamlit==1.30.0\n",
        "diffusers\n",
        "transformers\n",
        "torch\n",
        "accelerate\n",
        "ftfy\n",
        "Pillow\n",
        "    \"\"\")\n"
      ],
      "metadata": {
        "id": "lJKSpL00psm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}